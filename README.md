# MeMAD multimodal content analysis: collection of tools and libraries

The library consists of the following submodules:

## Aalto
 * PicSOM: <https://github.com/aalto-cbir/PicSOM>
 * DeepCaption: <https://github.com/aalto-cbir/DeepCaption>
 * Statistical tools for dataset analysis: <https://github.com/MeMAD-project/statistical-tools>
 * Multi-modal image caption translation: <https://github.com/Waino/OpenNMT-py/tree/develop_mmod>
 * Speech recognition training scripts for Finnish: <https://github.com/psmit/char-fin-2017>
 * Audio event classification: <https://github.com/ZhicunXu/AudioTagger>
 
## EURECOM
 * add your library and: its git/etc address here

## INA
 * inaSpeechSegmenter: <https://github.com/ina-foss/inaSpeechSegmenter>
 
